
{
    "credit": [
    ],
    "function": [
        {
            "operation": [
                {
                    "term": "Image analysis",
                    "uri": "http://edamontology.org/operation_3443"
                },
                {
                    "term": "Image annotation",
                    "uri": "http://edamontology.org/operation_3553"
                },
                {
                    "term": "Query and retrieval",
                    "uri": "http://edamontology.org/operation_0224"
                }
            ]
        }
    ],
    "labels": {
        "language": [
            "Python"
        ],
        "license": "MIT",
        "topic": [
            {
                "term": "Medical imaging",
                "uri": "http://edamontology.org/topic_3384"
            },
            {
                "term": "Machine learning",
                "uri": "http://edamontology.org/topic_3474"
            },
            {
                "term": "Model organisms",
                "uri": "http://edamontology.org/topic_0621"
            }
        ]
    },
    "publication": [
        {
            "abstract": "© 2019 Elsevier B.V.Deep neural networks enable highly accurate image segmentation, but require large amounts of manually annotated data for supervised training. Few-shot learning aims to address this shortcoming by learning a new class from a few annotated support examples. We introduce, a novel few-shot framework, for the segmentation of volumetric medical images with only a few annotated slices. Compared to other related works in computer vision, the major challenges are the absence of pre-trained networks and the volumetric nature of medical scans. We address these challenges by proposing a new architecture for few-shot segmentation that incorporates ‘squeeze & excite’ blocks. Our two-armed architecture consists of a conditioner arm, which processes the annotated support input and generates a task-specific representation. This representation is passed on to the segmenter arm that uses this information to segment the new query image. To facilitate efficient interaction between the conditioner and the segmenter arm, we propose to use ‘channel squeeze & spatial excitation’ blocks – a light-weight computational module – that enables heavy interaction between both the arms with negligible increase in model complexity. This contribution allows us to perform image segmentation without relying on a pre-trained model, which generally is unavailable for medical scans. Furthermore, we propose an efficient strategy for volumetric segmentation by optimally pairing a few slices of the support volume to all the slices of the query volume. We perform experiments for organ segmentation on whole-body contrast-enhanced CT scans from the Visceral Dataset. Our proposed model outperforms multiple baselines and existing approaches with respect to the segmentation accuracy by a significant margin. The source code is available at https://github.com/abhi4ssj/few-shot-segmentation.",
            "authors": [
                "Guha Roy A.",
                "Siddiqui S.",
                "Polsterl S.",
                "Navab N.",
                "Wachinger C."
            ],
            "cit_count": 0,
            "doi": "10.1016/J.MEDIA.2019.101587",
            "journal": "Medical Image Analysis",
            "pmid": "31630012",
            "title": "‘Squeeze & excite’ guided few-shot segmentation of volumetric images",
            "year": "2020-01-01"
        }
    ],
    "summary": {
        "biotoolsCURIE": "biotools:few-shot_segmentation",
        "biotoolsID": "few-shot_segmentation",
        "description": "'Squeeze & excite' guided few-shot segmentation of volumetric images.\n\nPyTorch implementation of 'Squeeze and Excite' Guided Few Shot Segmentation of Volumetric Scans.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'few-shot', 'segmenter'",
        "homepage": "https://github.com/abhi4ssj/few-shot-segmentation",
        "name": "few-shot segmentation"
    }
}