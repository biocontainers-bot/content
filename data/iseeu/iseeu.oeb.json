
{
    "credit": [
    ],
    "function": [
        {
            "operation": [
                {
                    "term": "Essential dynamics",
                    "uri": "http://edamontology.org/operation_3891"
                },
                {
                    "term": "Imputation",
                    "uri": "http://edamontology.org/operation_3557"
                }
            ]
        }
    ],
    "labels": {
        "license": "MIT",
        "topic": [
            {
                "term": "Statistics and probability",
                "uri": "http://edamontology.org/topic_2269"
            },
            {
                "term": "Machine learning",
                "uri": "http://edamontology.org/topic_3474"
            },
            {
                "term": "Critical care medicine",
                "uri": "http://edamontology.org/topic_3403"
            }
        ]
    },
    "publication": [
        {
            "abstract": "© 2019 Elsevier Inc.To improve the performance of Intensive Care Units (ICUs), the field of bio-statistics has developed scores which try to predict the likelihood of negative outcomes. These help evaluate the effectiveness of treatments and clinical practice, and also help to identify patients with unexpected outcomes. However, they have been shown by several studies to offer sub-optimal performance. Alternatively, Deep Learning offers state of the art capabilities in certain prediction tasks and research suggests deep neural networks are able to outperform traditional techniques. Nevertheless, a main impediment for the adoption of Deep Learning in healthcare is its reduced interpretability, for in this field it is crucial to gain insight into the why of predictions, to assure that models are actually learning relevant features instead of spurious correlations. To address this, we propose a deep multi-scale convolutional architecture trained on the Medical Information Mart for Intensive Care III (MIMIC-III) for mortality prediction, and the use of concepts from coalitional game theory to construct visual explanations aimed to show how important these inputs are deemed by the network. Results show our model attains a ROC AUC of 0.8735 (± 0.0025) which is competitive with the state of the art of Deep Learning mortality models trained on MIMIC-III data, while remaining interpretable. Supporting code can be found at https://github.com/williamcaicedo/ISeeU.",
            "authors": [
                "Caicedo-Torres W.",
                "Gutierrez J."
            ],
            "cit_count": 0,
            "doi": "10.1016/J.JBI.2019.103269",
            "journal": "Journal of Biomedical Informatics",
            "pmid": "31430550",
            "title": "ISeeU: Visually interpretable deep learning for mortality prediction inside the ICU",
            "year": "2019-10-01"
        }
    ],
    "summary": {
        "biotoolsCURIE": "biotools:ISeeU",
        "biotoolsID": "ISeeU",
        "description": "Visually interpretable deep learning for mortality prediction inside the ICU | To improve the performance of Intensive Care Units (ICUs), the field of bio-statistics has developed scores which try to predict the likelihood of negative outcomes. These help evaluate the effectiveness of treatments and clinical practice, and also help to identify patients with unexpected outcomes. However, they have been shown by several studies to offer sub-optimal performance. Alternatively, Deep Learning offers state of the art capabilities in certain prediction tasks and research suggests deep neural networks are able to outperform traditional techniques. Nevertheless, a main impediment for the adoption of Deep Learning in healthcare is its reduced interpretability, for in this field it is crucial to gain insight into the why of predictions, to assure that models are actually learning relevant features instead of spurious correlations",
        "homepage": "https://github.com/williamcaicedo/ISeeU",
        "name": "ISeeU"
    }
}