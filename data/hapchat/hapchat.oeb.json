
{
    "credit": [
        {
            "email": "murray.patterson@unimib.it",
            "name": "Murray D. Patterson",
            "typeEntity": "Person",
            "typeRoles": [
                "Primary contact"
            ]
        }
    ],
    "documentation": [
        {
            "type": "General",
            "url": "http://hapchat.algolab.eu"
        }
    ],
    "function": [
        {
            "operation": [
                {
                    "term": "Haplotype mapping",
                    "uri": "http://edamontology.org/operation_0487"
                }
            ]
        }
    ],
    "labels": {
        "language": [
            "C++",
            "Python"
        ],
        "license": "GPL-3.0",
        "operatingSystem": [
            "Linux",
            "Windows",
            "Mac"
        ],
        "toolType": [
            "Desktop application"
        ],
        "topic": [
            {
                "term": "Sequencing",
                "uri": "http://edamontology.org/topic_3168"
            }
        ]
    },
    "link": [
        {
            "type": "Mirror",
            "url": "https://github.com/AlgoLab/HapCHAT"
        }
    ],
    "publication": [
        {
            "abstract": "© 2018 The Author(s).Background: Haplotype assembly is the process of assigning the different alleles of the variants covered by mapped sequencing reads to the two haplotypes of the genome of a human individual. Long reads, which are nowadays cheaper to produce and more widely available than ever before, have been used to reduce the fragmentation of the assembled haplotypes since their ability to span several variants along the genome. These long reads are also characterized by a high error rate, an issue which may be mitigated, however, with larger sets of reads, when this error rate is uniform across genome positions. Unfortunately, current state-of-the-art dynamic programming approaches designed for long reads deal only with limited coverages. Results: Here, we propose a new method for assembling haplotypes which combines and extends the features of previous approaches to deal with long reads and higher coverages. In particular, our algorithm is able to dynamically adapt the estimated number of errors at each variant site, while minimizing the total number of error corrections necessary for finding a feasible solution. This allows our method to significantly reduce the required computational resources, allowing to consider datasets composed of higher coverages. The algorithm has been implemented in a freely available tool, HapCHAT: Haplotype Assembly Coverage Handling by Adapting Thresholds. An experimental analysis on sequencing reads with up to 60 × coverage reveals improvements in accuracy and recall achieved by considering a higher coverage with lower runtimes. Conclusions: Our method leverages the long-range information of sequencing reads that allows to obtain assembled haplotypes fragmented in a lower number of unphased haplotype blocks. At the same time, our method is also able to deal with higher coverages to better correct the errors in the original reads and to obtain more accurate haplotypes as a result. Availability: HapCHAT is available at http://hapchat.algolab.eu under the GNU Public License (GPL).",
            "authors": [
                "Beretta S.",
                "Patterson M.D.",
                "Zaccaria S.",
                "Della Vedova G.",
                "Bonizzoni P."
            ],
            "cit_count": 0,
            "doi": "10.1186/s12859-018-2253-8",
            "journal": "BMC Bioinformatics",
            "title": "HapCHAT: Adaptive haplotype assembly for efficiently leveraging high coverage in long reads",
            "type": "Primary",
            "year": "2018-07-03"
        }
    ],
    "summary": {
        "biotoolsCURIE": "biotools:hapchat",
        "biotoolsID": "hapchat",
        "description": "This method leverages the long-range information of sequencing reads that allows to obtain assembled haplotypes fragmented in a lower number of unphased haplotype blocks. At the same time, this method is also able to deal with higher coverages to better correct the errors in the original reads and to obtain more accurate haplotypes as a result.",
        "homepage": "http://hapchat.algolab.eu",
        "name": "HapCHAT"
    }
}